{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and classes required for this example:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd \n",
    "\n",
    "# Import dataset:\n",
    "#input file\n",
    "constituency=\"DublinWest2002_merged\"\n",
    "url='../data/processed/'+constituency+'_dist.csv'\n",
    "\n",
    "# Assign column names to dataset:\n",
    "\n",
    "# Convert dataset to a pandas dataframe:\n",
    "dataset = pd.read_csv(url,  na_values=[\"Missing\"], header=[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11818, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', '1', '2', '3', '4', '5', '6', '7', '8', 'Seq'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>Seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>11.629703</td>\n",
       "      <td>6.020797</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>7.138627</td>\n",
       "      <td>7.138627</td>\n",
       "      <td>1.615549</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.615549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004988</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>4.609772</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.067572</td>\n",
       "      <td>6.184658</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>11.629703</td>\n",
       "      <td>10.689247</td>\n",
       "      <td>1.615549</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>3.465545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11.629703</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>4.609772</td>\n",
       "      <td>7.138627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11813</th>\n",
       "      <td>11813</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>8.139410</td>\n",
       "      <td>7.138627</td>\n",
       "      <td>10.689247</td>\n",
       "      <td>12.298374</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>11814</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>8.139410</td>\n",
       "      <td>8.732125</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>10.689247</td>\n",
       "      <td>10.689247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>11815</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>8.139410</td>\n",
       "      <td>8.732125</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>10.689247</td>\n",
       "      <td>10.689247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>11816</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>8.139410</td>\n",
       "      <td>8.732125</td>\n",
       "      <td>12.298374</td>\n",
       "      <td>10.689247</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>11817</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>8.139410</td>\n",
       "      <td>8.732125</td>\n",
       "      <td>12.298374</td>\n",
       "      <td>10.689247</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>5.622277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11818 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          1          2          3          4          5  \\\n",
       "0               0   3.605551  11.629703   6.020797   5.622277   7.138627   \n",
       "1               1   1.615549   0.000000   1.004988   3.605551   1.581139   \n",
       "2               2   0.000000   3.067572   6.184658   4.301163   0.000000   \n",
       "3               3   3.605551  11.629703  10.689247   1.615549   7.071068   \n",
       "4               4  11.629703   3.605551   4.301163   7.071068   2.236068   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "11813       11813   4.301163   8.139410   7.138627  10.689247  12.298374   \n",
       "11814       11814   4.301163   8.139410   8.732125   7.071068   5.622277   \n",
       "11815       11815   4.301163   8.139410   8.732125   7.071068   5.622277   \n",
       "11816       11816   4.301163   8.139410   8.732125  12.298374  10.689247   \n",
       "11817       11817   4.301163   8.139410   8.732125  12.298374  10.689247   \n",
       "\n",
       "               6          7         8  Seq  \n",
       "0       7.138627   1.615549  5.000000    1  \n",
       "1       2.236068   4.609772  4.301163    1  \n",
       "2       0.000000   0.000000  0.000000    1  \n",
       "3       5.622277   3.465545  0.000000    1  \n",
       "4       4.609772   7.138627  0.000000    1  \n",
       "...          ...        ...       ...  ...  \n",
       "11813   7.071068   5.622277  0.000000    0  \n",
       "11814  10.689247  10.689247  0.000000    0  \n",
       "11815  10.689247  10.689247  0.000000    0  \n",
       "11816   5.622277   5.622277  0.000000    0  \n",
       "11817   5.622277   5.622277  0.000000    0  \n",
       "\n",
       "[11818 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset.columns)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use head() function to return the first 5 rows: \n",
    "dataset.head() \n",
    "# Assign values to the X and y variables:\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 9].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 305    0]\n",
      " [   5 2054]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       305\n",
      "           1       1.00      1.00      1.00      2059\n",
      "\n",
      "    accuracy                           1.00      2364\n",
      "   macro avg       0.99      1.00      1.00      2364\n",
      "weighted avg       1.00      1.00      1.00      2364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into random train and test subsets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) \n",
    "\n",
    "# Standardize features by removing mean and scaling to unit variance:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "# Use the KNN classifier to fit data:\n",
    "classifier = KNeighborsClassifier(n_neighbors=8)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "# Predict y data with classifier: \n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "# Print results: \n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 305    0]\n",
      " [   5 2054]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "print(conf_matrix) #display confusion matrix\n",
    "y_true = [\"good\", \"bad\"]\n",
    "#y_pred = [\"good\", \"bad\"]\n",
    "df_cm = pd.DataFrame(conf_matrix, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "df_cm.dtypes\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.title('Confusion Matrix' + \" KNN Classifer\")\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9979\n",
      "Classification Error Rate : 0.0021\n",
      "Precision : 1.0000\n",
      "Sensitivity/Recall :0.9976\n",
      "Specificity : 1.0000\n",
      "False Positive Rate : 0.0000\n",
      "False Negative Rate : 0.0024\n",
      "F1-Measure : 0.9988\n",
      "cross val score: : 0.9962\n"
     ]
    }
   ],
   "source": [
    "#[row, column]\n",
    "TP = conf_matrix[1, 1]\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "\n",
    "# Classification Accuracy\n",
    "# use float to perform true division, not integer division\n",
    "accuracy = ((TP + TN) / float(TP + TN + FP + FN))\n",
    "#accuracy = accuracy_score(Y_test, y_pred_class)\n",
    "print(\"Accuracy : %.4f\" %accuracy)\n",
    "\n",
    "# Classification Error/Misclassification Rate = 1 - accuracy\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "print(\"Classification Error Rate : %.4f\" %(classification_error))\n",
    "\n",
    "# Precision\n",
    "precision = TP / float(TP + FP)\n",
    "print(\"Precision : %.4f\" %(precision))\n",
    "#print(\"Precision : %.4f\" %(precision_score(Y_test, y_pred)))\n",
    "\n",
    "# Sensitivity or Recall or True Positive Rate\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print(\"Sensitivity/Recall :%.4f\" %(sensitivity))\n",
    "#print(\"Sensitivity/Recall : %.4f\" %(recall_score(Y_test, y_pred)))\n",
    "\n",
    "# Specificity oe true negative rate\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"Specificity : %.4f\" %(specificity))\n",
    "\n",
    "# False Positive Rate (1 - specificity))\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "print(\"False Positive Rate : %.4f\" %(false_positive_rate))\n",
    "\n",
    "# False Negative Rate\n",
    "false_negative_rate = FN / float(TP + FN)\n",
    "print(\"False Negative Rate : %.4f\" %(false_negative_rate))\n",
    "\n",
    "# F1 Measure (F1 Score) = 2 * ((precision * sensitivity)/(precision + sensitivity))\n",
    "F1_measure = 2* ((precision * sensitivity)/(precision + sensitivity))\n",
    "print(\"F1-Measure : %.4f\" %(F1_measure))\n",
    "\n",
    "# Cross Validation is used to check the model is not overfitting\n",
    "c_v_score = cross_val_score(classifier,X_train,y_train,cv = 10).mean()\n",
    "print(\"cross val score: : %.4f\" %(c_v_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1          2          3          4          5          6  \\\n",
      "0    3.605551  11.629703   6.020797   5.622277   7.138627   7.138627   \n",
      "1    1.615549   0.000000   1.004988   3.605551   1.581139   2.236068   \n",
      "2    0.000000   3.067572   6.184658   4.301163   0.000000   0.000000   \n",
      "3    3.605551  11.629703  10.689247   1.615549   7.071068   5.622277   \n",
      "4   11.629703   3.605551   4.301163   7.071068   2.236068   4.609772   \n",
      "5    4.301163   3.605551   6.363961   5.622277   0.000000   7.138627   \n",
      "6    7.138627   7.138627  10.689247   6.020797   0.000000   0.000000   \n",
      "7    0.000000   7.138627   4.609772   7.433034   8.732125   2.915476   \n",
      "8    7.138627   0.000000   3.067572   2.915476   6.363961   0.000000   \n",
      "9    7.138627  10.689247   6.020797   2.915476   3.067572   1.004988   \n",
      "10   4.301163  11.629703  12.298374   8.732125   7.138627   5.622277   \n",
      "11   4.301163  11.629703  12.298374   8.732125   7.138627   5.622277   \n",
      "12   4.301163   8.139410   7.138627   5.622277   7.071068  12.298374   \n",
      "13   4.301163   8.139410   7.138627  10.689247  12.298374   7.071068   \n",
      "14   4.301163   8.139410   7.138627   5.622277   7.071068  12.298374   \n",
      "15   4.301163   8.139410   7.138627  10.689247  12.298374   7.071068   \n",
      "16   4.301163   8.139410   8.732125   7.071068   5.622277  10.689247   \n",
      "17   4.301163   8.139410   8.732125   7.071068   5.622277  10.689247   \n",
      "18   4.301163   8.139410   8.732125  12.298374  10.689247   5.622277   \n",
      "19   4.301163   8.139410   8.732125  12.298374  10.689247   5.622277   \n",
      "\n",
      "            7         8  \n",
      "0    1.615549  5.000000  \n",
      "1    4.609772  4.301163  \n",
      "2    0.000000  0.000000  \n",
      "3    3.465545  0.000000  \n",
      "4    7.138627  0.000000  \n",
      "5    4.609772  7.433034  \n",
      "6    0.000000  0.000000  \n",
      "7    6.363961  0.000000  \n",
      "8    0.000000  0.000000  \n",
      "9    0.707107  0.000000  \n",
      "10   5.622277  0.000000  \n",
      "11   5.622277  0.000000  \n",
      "12  10.689247  0.000000  \n",
      "13   5.622277  0.000000  \n",
      "14  10.689247  0.000000  \n",
      "15   5.622277  0.000000  \n",
      "16  10.689247  0.000000  \n",
      "17  10.689247  0.000000  \n",
      "18   5.622277  0.000000  \n",
      "19   5.622277  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Import dataset and classes needed in this example:\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Gaussian Naive Bayes classifier:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Import dataset:\n",
    "#input file\n",
    "constituency=\"DublinWest2002_merged\"\n",
    "url='../data/processed/'+constituency+'toptail_dist.csv'\n",
    "\n",
    "# Load dataset: \n",
    "#data = load_iris()\n",
    "\n",
    "\n",
    "# Convert dataset to a pandas dataframe:\n",
    "data = pd.read_csv(url,  na_values=[\"Missing\"], header=[0]) \n",
    "\n",
    "# Organize data:\n",
    "label_names = 'Seq'\n",
    "labels = data['Seq']\n",
    "#drop the numbers column (#df=df.drop(['No.'], 1))\n",
    "data = data.drop(data.columns[[0]], axis=1)  # df.columns is zero-based pd.Index\n",
    "data= data.drop(columns=['Seq'], axis=1)  \n",
    "print(data)\n",
    "feature_names = data.columns\n",
    "features = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq\n",
      "Index(['1', '2', '3', '4', '5', '6', '7', '8'], dtype='object')\n",
      "            1          2          3          4          5          6  \\\n",
      "0    3.605551  11.629703   6.020797   5.622277   7.138627   7.138627   \n",
      "1    1.615549   0.000000   1.004988   3.605551   1.581139   2.236068   \n",
      "2    0.000000   3.067572   6.184658   4.301163   0.000000   0.000000   \n",
      "3    3.605551  11.629703  10.689247   1.615549   7.071068   5.622277   \n",
      "4   11.629703   3.605551   4.301163   7.071068   2.236068   4.609772   \n",
      "5    4.301163   3.605551   6.363961   5.622277   0.000000   7.138627   \n",
      "6    7.138627   7.138627  10.689247   6.020797   0.000000   0.000000   \n",
      "7    0.000000   7.138627   4.609772   7.433034   8.732125   2.915476   \n",
      "8    7.138627   0.000000   3.067572   2.915476   6.363961   0.000000   \n",
      "9    7.138627  10.689247   6.020797   2.915476   3.067572   1.004988   \n",
      "10   4.301163  11.629703  12.298374   8.732125   7.138627   5.622277   \n",
      "11   4.301163  11.629703  12.298374   8.732125   7.138627   5.622277   \n",
      "12   4.301163   8.139410   7.138627   5.622277   7.071068  12.298374   \n",
      "13   4.301163   8.139410   7.138627  10.689247  12.298374   7.071068   \n",
      "14   4.301163   8.139410   7.138627   5.622277   7.071068  12.298374   \n",
      "15   4.301163   8.139410   7.138627  10.689247  12.298374   7.071068   \n",
      "16   4.301163   8.139410   8.732125   7.071068   5.622277  10.689247   \n",
      "17   4.301163   8.139410   8.732125   7.071068   5.622277  10.689247   \n",
      "18   4.301163   8.139410   8.732125  12.298374  10.689247   5.622277   \n",
      "19   4.301163   8.139410   8.732125  12.298374  10.689247   5.622277   \n",
      "\n",
      "            7         8  \n",
      "0    1.615549  5.000000  \n",
      "1    4.609772  4.301163  \n",
      "2    0.000000  0.000000  \n",
      "3    3.465545  0.000000  \n",
      "4    7.138627  0.000000  \n",
      "5    4.609772  7.433034  \n",
      "6    0.000000  0.000000  \n",
      "7    6.363961  0.000000  \n",
      "8    0.000000  0.000000  \n",
      "9    0.707107  0.000000  \n",
      "10   5.622277  0.000000  \n",
      "11   5.622277  0.000000  \n",
      "12  10.689247  0.000000  \n",
      "13   5.622277  0.000000  \n",
      "14  10.689247  0.000000  \n",
      "15   5.622277  0.000000  \n",
      "16  10.689247  0.000000  \n",
      "17  10.689247  0.000000  \n",
      "18   5.622277  0.000000  \n",
      "19   5.622277  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Print data:\n",
    "print(label_names)\n",
    "#print('Class label = ', labels[0])\n",
    "print(feature_names)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into random train and test subsets:\n",
    "train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# Initialize classifier:\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the classifier:\n",
    "model = gnb.fit(train, train_labels)\n",
    "# Make predictions with the classifier:\n",
    "predictive_labels = gnb.predict(test)\n",
    "print(predictive_labels)\n",
    "\n",
    "# Evaluate label (subsets) accuracy:\n",
    "print(accuracy_score(test_labels, predictive_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
